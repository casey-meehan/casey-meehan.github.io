<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Casey Meehan</title>
  <meta property="og:title" content="Casey Meehan" />
  <meta property="og:locale" content="en_US" />
  <meta name="description" content="Casey's website!" />
  <meta property="og:description" content="Casey's website" />
  <meta property="og:site_name" content="Casey Meehan" />
  <link rel="stylesheet" href="caseytemplate.css">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
</head>
<body>
  <center>

    <nav class="navbar navbar-expand-lg navbar-light bg-light">
        <a class="navbar-brand" href="#">Casey Meehan</a>
        <div class="collapse navbar-collapse" id="navbarText">
          <ul class="navbar-nav">
            <li class="nav-item">
              <a class="nav-link" href="#projects">Projects</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="#contact">Contact</a>
            </li>
          </ul>
        </div>
    </nav>

  <br>
    <img src="casey_at_de_beach.jpg"/>
    <br>
    <div id="about">
      <p>
      I'm a fourth year PhD student at UCSD advised by <a href="https://cseweb.ucsd.edu/~kamalika/">Kamalika Chaudhuri</a>. My research focuses on personal data privacy in machine learning. I'm especially interested in the subtle problem of privacy definitions. The notion of 'meaningful' data privacy changes from one situation to another --- how to define it in a way that is mathematically precise but easy to describe in plain words is as challenging as it is intriguing.   
      </p>

    </div>
    <div id="projects">

      <h2>Projects</h2>
      <ul>
        <li>Casey Meehan, Amrita Roy Chowdhury, Kamalika Chaudhuri, Somesh Jha. "<a class="paper-link" href="https://arxiv.org/abs/2106.06603">A Shuffling Framework for Local Differential Privacy</a>" Preprint, 2021 <br> <br>
	Here we formalize how non-uniform random shuffling of users' private data can provide a strong notion of inferential privacy (preventing inference using others data) while still preserving broad trends within the aggregate. </li>	 
        <li>Casey Meehan, Kamalika Chaudhuri. "<a class = "paper-link" href="https://arxiv.org/abs/2102.11955">Location Trace Privacy Under Conditional Priors</a>" AISTATS, 2021 <br> <br>
 	In this project we analyze how to provide meaningful local privacy to sequences of individuals' locations when they are captured close together in time (traces). See corresponding blogpost <a href="https://ucsdml.github.io/jekyll/update/2021/05/10/location-trace-privacy.html">here</a>. </li>
        <li>Casey Meehan, Kamalika Chaudhuri, Sanjoy Dasgupta. "<a class = "paper-link" href="https://arxiv.org/abs/2004.05675">A Non-Parametric Test to Detect Data-Copying in Generative Models</a>" AISTATS, 2020" <br> <br>
	It is not clear how to determine whether a generative model is overfitting its dataset. This problem is exasperated by the fact that contemporary generative models have intractable likelihoods. In this project, we propose a new notion of overfitting, data-copying, wherein a generative model produces examples that are closer to its training set than a held out test set woudl be. See the companion blogpost <a href="https://ucsdml.github.io/jekyll/update/2020/08/03/how-to-detect-data-copying-in-generative-models.html">here</a>.</li>
      </ul>

    </div>
    <div id="contact">
      <h2>Contact</h2>
      Email: cmeehan at eng.ucsd.edu <br>
      Twitter: <a href="https://twitter.com/kc_meehan">@kc_meehan</a> <br>
      <a href="cv.pdf">CV</a>      
    </div>
    <div id="scroll-padding">
    </div>
  </center>

</body>

</html>
